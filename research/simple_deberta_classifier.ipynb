{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de297155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir(\"/Users/morizin/Documents/Code/jigsaw-competition\")\n",
    "\n",
    "import re\n",
    "from src.jigsaw.utils.common import read_csv\n",
    "from src.jigsaw import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5421009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    fold : int = 4\n",
    "    dataset : list[str] = ['artifacts/data/folded_cleaned_raw']\n",
    "    files: list[str] = ['train.csv']\n",
    "    url2sem : bool = False\n",
    "    features : list[str] = ['body', 'subreddit', 'rule', 'positive_example_1', 'positive_example_2', 'negative_example_1', 'negative_example_2']\n",
    "    labels : list[str] | str = 'rule_violation'\n",
    "\n",
    "\n",
    "    truncation : bool | str = True\n",
    "    model_name : str = 'microsoft/deberta-v3-small'\n",
    "    padding : bool | str = 'max_length'\n",
    "    max_length : int = 2048\n",
    "\n",
    "    outdir : str = './model'\n",
    "    nepochs : int = 1\n",
    "    learning_rate : float = 2e-5\n",
    "    batch_size: int = 4\n",
    "    gradient_accumulation_step : int = 1\n",
    "    weight_decay : float = 0.01\n",
    "    warmup_ratio: float = 0.1\n",
    "\n",
    "config = CFG()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f314f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.core.frame import DataFrame\n",
    "import os\n",
    "\n",
    "def get_datas(config: CFG) -> DataFrame:\n",
    "    data_coll = []\n",
    "    for dataset in config.dataset:\n",
    "        for file in config.files:\n",
    "            data = read_csv(os.path.join(dataset, file))\n",
    "            columns = config.features\n",
    "            if all([col in data.columns for col in columns]):\n",
    "                data_coll.append(data)\n",
    "            else:\n",
    "                logger.error(\n",
    "                    f\"The dataset can't be inlcuded as it have unmatched columns names {data.columns}\"\n",
    "                )\n",
    "    data = pd.concat(data_coll, axis=0)\n",
    "    return data\n",
    "\n",
    "data = get_datas(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f3dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from ensure import ensure_annotations\n",
    "from pandas.core.frame import DataFrame\n",
    "from transformers import AutoTokenizer\n",
    "from transformers.models.deberta_v2.tokenization_deberta_v2 import DebertaV2Tokenizer\n",
    "from transformers.models.deberta_v2.tokenization_deberta_v2_fast import (\n",
    "    DebertaV2TokenizerFast,\n",
    ")\n",
    "from pandas.api.types import is_string_dtype\n",
    "from src.jigsaw.utils.data import build_prompt, url_to_semantics\n",
    "from src.jigsaw.utils.common import read_csv\n",
    "from typing import Dict\n",
    "import torch\n",
    "\n",
    "\n",
    "class ClassifierDataset(Dataset):\n",
    "    @ensure_annotations\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: CFG,\n",
    "        data: DataFrame | str,\n",
    "        tokenizer: DebertaV2Tokenizer | DebertaV2TokenizerFast | str,\n",
    "    ):\n",
    "        if isinstance(data, str):\n",
    "            data = read_csv(data)\n",
    "\n",
    "        if isinstance(data, DataFrame):\n",
    "            self.data = data\n",
    "        else:\n",
    "            error = f\"'data' can be either str or pd.DataFrame. 'data' has type {type(data).__name__}\"\n",
    "            logger.error(error)\n",
    "            raise Exception(error)\n",
    "\n",
    "        if isinstance(tokenizer, str):\n",
    "            tokenizer = AutoTokenizer.from_pretrained(tokenizer)\n",
    "            \n",
    "        if isinstance(tokenizer, (DebertaV2Tokenizer, DebertaV2TokenizerFast)):\n",
    "            self.tokenizer = tokenizer\n",
    "        else:\n",
    "            error = f\"'tokenizer' can be either str, DebertaV2Tokenizer, DebertaV2TokenizerFast. 'tokenizer' has type {type(tokenizer).__name__}\"\n",
    "            logger.error(error)\n",
    "            raise Exception(error)\n",
    "\n",
    "        if config.url2sem:\n",
    "            for (col, dtype) in data.dtypes.items():\n",
    "                if is_string_dtype(dtype):\n",
    "                    data[col] = data[col] + data[col].apply(url_to_semantics)\n",
    "\n",
    "        self.completion = data.apply(build_prompt, axis=1).to_list()\n",
    "        \n",
    "        self.encoding = self.tokenizer(\n",
    "            self.completion, truncation=config.truncation, padding = config.padding, max_length=config.max_length\n",
    "        )\n",
    "\n",
    "        if isinstance(config.labels, str):\n",
    "            config.labels = [config.labels]\n",
    "\n",
    "        if any([col in data.columns for col in config.labels]):\n",
    "            self.labels = data[config.labels].to_numpy()\n",
    "        else:\n",
    "            self.labels = None\n",
    "\n",
    "    def __len__(self,) -> int:\n",
    "        assert len(self.encoding['input_ids']) == len(self.labels), f\"Input and Output length mismatch {len(self.encoding)} != {len(self.labels)}\"\n",
    "        return len(self.encoding['input_ids'])\n",
    "    \n",
    "    def __getitem__(self, idx) -> Dict[str, torch.Tensor]: \n",
    "        items = {key : torch.tensor(value[idx]) for (key, value) in self.encoding.items()}\n",
    "        if self.labels is not None:\n",
    "            items['label'] = torch.tensor(self.labels[idx].flatten())\n",
    "        return items\n",
    "\n",
    "\n",
    "train_dataset = ClassifierDataset(\n",
    "    config, data, config.model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03be6237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# train_dataloader = DataLoader(\n",
    "#     train_dataset,\n",
    "#     batch_size=16,\n",
    "#     shuffle = True,\n",
    "#     num_workers=0,\n",
    "#     pin_memory=True\n",
    "# )\n",
    "\n",
    "# for i in train_dataloader:\n",
    "#     print(i['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a521735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(config.model_name, trust_remote_code = True)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, 1)\n",
    "del model.dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968280f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e708e559",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=config.outdir,\n",
    "    overwrite_output_dir=True,\n",
    "    do_train=True,\n",
    "    per_device_train_batch_size=config.batch_size,\n",
    "    gradient_accumulation_steps= config.gradient_accumulation_step,\n",
    "    learning_rate=config.learning_rate,\n",
    "    weight_decay=config.weight_decay,\n",
    "    warmup_ratio= config.warmup_ratio,\n",
    "    num_train_epochs= config.nepochs,\n",
    "    report_to= 'none',\n",
    "    save_strategy='no'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model, \n",
    "    args = training_args,\n",
    "    train_dataset=train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e13c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0486a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jigsaw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
