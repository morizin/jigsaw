{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1413b453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4898340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0dedb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3_client.upload_file(\"../config/config.yaml\",\"jigsaw-model\",\"config/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e265a7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../artifact/11_19_2025_08_54_12/models/deberta1/model.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [08:33<1:08:25, 513.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../artifact/11_19_2025_08_54_12/models/deberta1/added_tokens.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [08:33<24:41, 211.61s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../artifact/11_19_2025_08_54_12/models/deberta1/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3/9 [08:34<11:31, 115.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../artifact/11_19_2025_08_54_12/models/deberta1/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [08:34<05:49, 69.90s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../artifact/11_19_2025_08_54_12/models/deberta1/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [08:35<02:59, 44.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../artifact/11_19_2025_08_54_12/models/deberta1/tokenizer.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6/9 [08:41<01:35, 31.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../artifact/11_19_2025_08_54_12/models/deberta1/spm.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7/9 [08:42<00:43, 21.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../artifact/11_19_2025_08_54_12/models/deberta1/training_params.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8/9 [08:43<00:14, 14.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../artifact/11_19_2025_08_54_12/models/deberta1/training_args.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [08:43<00:00, 58.17s/it]\n"
     ]
    }
   ],
   "source": [
    "import os, tqdm\n",
    "def uploadDirectory(path,bucketname):\n",
    "    for root,dirs,files in os.walk(path):\n",
    "        for file in tqdm.tqdm(files):\n",
    "            print(root, file, sep = \"/\")\n",
    "            s3_client.upload_file(os.path.join(root,file),bucketname,file)\n",
    "\n",
    "uploadDirectory(\"../artifact/11_19_2025_08_54_12/models/deberta1\", \"jigsaw-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1badb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RepoUrl('https://huggingface.co/morizin/jigsaw-deberta-base', endpoint='https://huggingface.co', repo_type='model', repo_id='morizin/jigsaw-deberta-base')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, create_repo\n",
    "create_repo(repo_id=\"morizin/jigsaw-deberta-base\", repo_type=\"model\", exist_ok=True, private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02c94f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files (3 / 3): 100%|██████████|  740MB /  740MB, 6.42MB/s  \n",
      "New Data Upload: 100%|██████████|  738MB /  738MB, 6.42MB/s  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/morizin/jigsaw-deberta-base/commit/b557ded01c75366e046ee75ad8fdc119068894b7', commit_message='uploaded model', commit_description='', oid='b557ded01c75366e046ee75ad8fdc119068894b7', pr_url=None, repo_url=RepoUrl('https://huggingface.co/morizin/jigsaw-deberta-base', endpoint='https://huggingface.co', repo_type='model', repo_id='morizin/jigsaw-deberta-base'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api = HfApi()\n",
    "api.upload_folder(\n",
    "    folder_path=\"/Users/morizin/Documents/Code/jigsaw-competition/artifact/11_19_2025_08_54_12/models/deberta1\",\n",
    "    repo_id=\"morizin/jigsaw-deberta-base\",\n",
    "    commit_message=\"uploaded model\", \n",
    "    repo_type=\"model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfccaf2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model 'morizin/jigsaw-deberta-base' doesn't support task 'text-classification'. Supported tasks: 'None', got: 'text-classification'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      5\u001b[39m dotenv.load_dotenv()\n\u001b[32m      7\u001b[39m client = InferenceClient(\n\u001b[32m      8\u001b[39m     provider=\u001b[33m\"\u001b[39m\u001b[33mhf-inference\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     token=os.getenv(\u001b[33m\"\u001b[39m\u001b[33mHF_TOKEN\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m result = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext_classification\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mI like you. I love you\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmorizin/jigsaw-deberta-base\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code/jigsaw-competition/.venv/lib/python3.11/site-packages/huggingface_hub/inference/_client.py:1910\u001b[39m, in \u001b[36mInferenceClient.text_classification\u001b[39m\u001b[34m(self, text, model, top_k, function_to_apply)\u001b[39m\n\u001b[32m   1908\u001b[39m model_id = model \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model\n\u001b[32m   1909\u001b[39m provider_helper = get_provider_helper(\u001b[38;5;28mself\u001b[39m.provider, task=\u001b[33m\"\u001b[39m\u001b[33mtext-classification\u001b[39m\u001b[33m\"\u001b[39m, model=model_id)\n\u001b[32m-> \u001b[39m\u001b[32m1910\u001b[39m request_parameters = \u001b[43mprovider_helper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprepare_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1911\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1912\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1913\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_to_apply\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_to_apply\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1914\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_k\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1920\u001b[39m response = \u001b[38;5;28mself\u001b[39m._inner_post(request_parameters)\n\u001b[32m   1921\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m TextClassificationOutputElement.parse_obj_as_list(response)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code/jigsaw-competition/.venv/lib/python3.11/site-packages/huggingface_hub/inference/_providers/_common.py:93\u001b[39m, in \u001b[36mTaskProviderHelper.prepare_request\u001b[39m\u001b[34m(self, inputs, parameters, headers, model, api_key, extra_payload)\u001b[39m\n\u001b[32m     90\u001b[39m api_key = \u001b[38;5;28mself\u001b[39m._prepare_api_key(api_key)\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m# mapped model from HF model ID\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m provider_mapping_info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_mapping_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# default HF headers + user headers (to customize in subclasses)\u001b[39;00m\n\u001b[32m     96\u001b[39m headers = \u001b[38;5;28mself\u001b[39m._prepare_headers(headers, api_key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code/jigsaw-competition/.venv/lib/python3.11/site-packages/huggingface_hub/inference/_providers/hf_inference.py:45\u001b[39m, in \u001b[36mHFInferenceTask._prepare_mapping_info\u001b[39m\u001b[34m(self, model)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     42\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTask \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.task\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m has no recommended model for HF Inference. Please specify a model\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     43\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m explicitly. Visit https://huggingface.co/tasks for more info.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     44\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[43m_check_supported_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m InferenceProviderMapping(\n\u001b[32m     47\u001b[39m     provider=\u001b[33m\"\u001b[39m\u001b[33mhf-inference\u001b[39m\u001b[33m\"\u001b[39m, providerId=model_id, hf_model_id=model_id, task=\u001b[38;5;28mself\u001b[39m.task, status=\u001b[33m\"\u001b[39m\u001b[33mlive\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     48\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code/jigsaw-competition/.venv/lib/python3.11/site-packages/huggingface_hub/inference/_providers/hf_inference.py:203\u001b[39m, in \u001b[36m_check_supported_task\u001b[39m\u001b[34m(model, task)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;66;03m# For all other tasks, just check pipeline tag\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pipeline_tag != task:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    204\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt support task \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Supported tasks: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipeline_tag\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, got: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    205\u001b[39m     )\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Model 'morizin/jigsaw-deberta-base' doesn't support task 'text-classification'. Supported tasks: 'None', got: 'text-classification'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "client = InferenceClient(\n",
    "    provider=\"hf-inference\",\n",
    "    token=os.getenv(\"HF_TOKEN\")\n",
    ")\n",
    "\n",
    "result = client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edc1d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from localstack.sdk import aws\n",
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e38505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = aws.AWSClient()\n",
    "client.configuration.host\n",
    "\n",
    "sqs_client = boto3.client(\n",
    "    \"sqs\",\n",
    "    endpoint_url=client.configuration.host,\n",
    "    region_name=\"us-east-1\",\n",
    "    aws_access_key_id=\"test\",\n",
    "    aws_secret_access_key=\"test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ccc239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session(profile_name='localstack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8659627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = session.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=client.configuration.host, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "003bf897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'ebc755eb-3af2-4185-b2f6-4025bfd8a49e',\n",
       "  'HostId': 's9lzHYrFp76ZVxRcpX9+5cjAnEH2ROuNkd2BHfIa6UkFVdtjf5mKR3/eTPFvsiP/XV/VLi31234=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'server': 'TwistedWeb/24.3.0',\n",
       "   'date': 'Wed, 19 Nov 2025 18:36:05 GMT',\n",
       "   'access-control-allow-origin': '*',\n",
       "   'access-control-allow-methods': 'HEAD,GET,PUT,POST,DELETE,OPTIONS,PATCH',\n",
       "   'access-control-allow-headers': 'authorization,cache-control,content-length,content-md5,content-type,etag,location,x-amz-acl,x-amz-content-sha256,x-amz-date,x-amz-request-id,x-amz-security-token,x-amz-tagging,x-amz-target,x-amz-user-agent,x-amz-version-id,x-amzn-requestid,x-localstack-target,amz-sdk-invocation-id,amz-sdk-request,x-amz-log-type',\n",
       "   'access-control-expose-headers': 'etag,x-amz-version-id,x-amz-log-result,x-amz-executed-version,x-amz-function-error',\n",
       "   'vary': 'Origin',\n",
       "   'location': '/jigsaw-model',\n",
       "   'x-amz-request-id': 'ebc755eb-3af2-4185-b2f6-4025bfd8a49e',\n",
       "   'x-amz-id-2': 's9lzHYrFp76ZVxRcpX9+5cjAnEH2ROuNkd2BHfIa6UkFVdtjf5mKR3/eTPFvsiP/XV/VLi31234=',\n",
       "   'x-localstack': 'true',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Location': '/jigsaw-model'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_client.create_bucket(Bucket = \"jigsaw-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bba6304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def UploadFolder(filepath, bucket_name):\n",
    "    for root, dir, files in os.walk(filepath):\n",
    "        for file in files:\n",
    "            s3_client.upload_file(os.path.join(root, file), bucket_name, file)\n",
    "\n",
    "UploadFolder(\"../artifact/11_19_2025_08_54_12/models/deberta1\", \"jigsaw-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb5d690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'        def _api_call(self, *args, **kwargs):\\n            # We\\'re accepting *args so that we can give a more helpful\\n            # error message than TypeError: _api_call takes exactly\\n            # 1 argument.\\n            if args:\\n                raise TypeError(\\n                    f\"{py_operation_name}() only accepts keyword arguments.\"\\n                )\\n            # The \"self\" in this scope is referring to the BaseClient.\\n            return self._make_api_call(operation_name, kwargs)\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "ecr_client.create_repository()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8dc61d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'repository': {'repositoryArn': 'arn:aws:ecr:us-east-1:000000000000:repository/jigsaw-inference',\n",
       "  'registryId': '000000000000',\n",
       "  'repositoryName': 'jigsaw-inference',\n",
       "  'repositoryUri': '000000000000.dkr.ecr.us-east-1.localhost.localstack.cloud:4566/jigsaw-inference',\n",
       "  'createdAt': datetime.datetime(2025, 11, 20, 0, 24, 2, tzinfo=tzlocal()),\n",
       "  'imageTagMutability': 'MUTABLE',\n",
       "  'imageScanningConfiguration': {'scanOnPush': True},\n",
       "  'encryptionConfiguration': {'encryptionType': 'AES256'}},\n",
       " 'ResponseMetadata': {'RequestId': '8fc0ac46-02c6-49d2-a2e8-93850432f3c2',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'server': 'TwistedWeb/24.3.0',\n",
       "   'date': 'Wed, 19 Nov 2025 18:54:02 GMT',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '436',\n",
       "   'x-amzn-requestid': '8fc0ac46-02c6-49d2-a2e8-93850432f3c2',\n",
       "   'x-localstack': 'true'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecr_client = boto3.client(\"ecr\", endpoint_url = client.configuration.host)\n",
    "ecr_client.create_repository(\n",
    "    repositoryName = \"jigsaw-inference\",\n",
    "    imageTagMutability = \"MUTABLE\",\n",
    "    imageScanningConfiguration = {\n",
    "        \"scanOnPush\" : True\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e496b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_client = session.client(\"iam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f6a7f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Users': [],\n",
       " 'IsTruncated': False,\n",
       " 'ResponseMetadata': {'RequestId': 'aa675ded-371f-49fd-9321-4754af14d8fe',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'server': 'TwistedWeb/24.3.0',\n",
       "   'date': 'Wed, 19 Nov 2025 19:53:22 GMT',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '300',\n",
       "   'x-amzn-requestid': 'aa675ded-371f-49fd-9321-4754af14d8fe',\n",
       "   'x-localstack': 'true'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iam_client.list_users()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "66626ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Roles': [{'Path': '/',\n",
       "   'RoleName': 'myrole',\n",
       "   'RoleId': 'AROAQAAAAAAANTBNVTQAJ',\n",
       "   'Arn': 'arn:aws:iam::000000000000:role/myrole',\n",
       "   'CreateDate': datetime.datetime(2025, 11, 19, 19, 54, 5, 506273, tzinfo=tzutc()),\n",
       "   'AssumeRolePolicyDocument': {'Version': '2012-10-17',\n",
       "    'Statement': [{'Effect': 'Allow',\n",
       "      'Principal': {'AWS': 'arn:aws:iam::000000000000:root'},\n",
       "      'Action': 'sts:AssumeRole'}]},\n",
       "   'MaxSessionDuration': 3600}],\n",
       " 'IsTruncated': False,\n",
       " 'ResponseMetadata': {'RequestId': '71dbf639-68e9-4f6c-b5d3-4845b561ac3b',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'server': 'TwistedWeb/24.3.0',\n",
       "   'date': 'Wed, 19 Nov 2025 20:03:03 GMT',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '800',\n",
       "   'x-amzn-requestid': '71dbf639-68e9-4f6c-b5d3-4845b561ac3b',\n",
       "   'x-localstack': 'true'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iam_client.list_roles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed385ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker build -t '000000000000.dkr.ecr.us-east-1.localhost.localstack.cloud:4566/jigsaw-inference' src/backend\n",
    "# docker push 000000000000.dkr.ecr.us-east-1.localhost.localstack.cloud:4566/jigsaw-inference:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "51c796ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "\n",
    "ecr_client = boto3.client(\"ecr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63557b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "docker build -t public.ecr.aws/l7w7c8z7/morizin/jigsaw-inference:latest src/backend\n",
    "docker push public.ecr.aws/l7w7c8z7/morizin/jigsaw-inference:latest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jigsaw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
